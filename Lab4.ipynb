{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "# Definicion de ambiente\n",
    "class InventoryEnvironment:\n",
    "    def __init__(self):\n",
    "        self.products = ['product_A', 'product_B']\n",
    "        self.max_stock = 10 # Pueden cambiar este número si gustan\n",
    "        self.demand = {'product_A': [0, 1, 2], 'product_B': [0, 1, 2]}\n",
    "        self.restock_cost = {'product_A': 5, 'product_B': 7}\n",
    "        self.sell_price = {'product_A': 10, 'product_B': 15}\n",
    "        self.state = None \n",
    "    def reset(self):\n",
    "        self.state = {product: random.randint(0, self.max_stock) for product in self.products}\n",
    "        return self.state\n",
    "    \n",
    "    def step(self, action):\n",
    "        reward = 0\n",
    "        for product in self.products:\n",
    "            stock = self.state[product]\n",
    "            restock = action[product]\n",
    "            self.state[product] = min(self.max_stock, stock + restock)\n",
    "            demand = random.choice(self.demand[product])\n",
    "            sales = min(demand, self.state[product])\n",
    "            self.state[product] -= sales\n",
    "            reward += sales * self.sell_price[product] - restock * self.restock_cost[product]\n",
    "        return self.state, reward\n",
    "# Init el ambiente\n",
    "env = InventoryEnvironment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para generar un episodio\n",
    "def generate_episode(env, policy, max_steps=10):\n",
    "    state = env.reset()\n",
    "    episode = []\n",
    "    for _ in range(max_steps):\n",
    "        action = policy(state)\n",
    "        next_state, reward = env.step(action)\n",
    "        episode.append((state, action, reward, next_state))\n",
    "        state = next_state\n",
    "    return episode\n",
    "\n",
    "# Política de inventario específica (ejemplo simple que reabastece al azar)\n",
    "def random_policy(state):\n",
    "    return {product: random.randint(0, 2) for product in state.keys()}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "({'product_A': 6, 'product_B': 4}, {'product_A': 0, 'product_B': 0}, 0, {'product_A': 6, 'product_B': 4})\n",
      "({'product_A': 6, 'product_B': 4}, {'product_A': 1, 'product_B': 0}, 5, {'product_A': 6, 'product_B': 4})\n",
      "({'product_A': 6, 'product_B': 4}, {'product_A': 0, 'product_B': 1}, 18, {'product_A': 6, 'product_B': 4})\n",
      "({'product_A': 6, 'product_B': 4}, {'product_A': 1, 'product_B': 1}, 18, {'product_A': 6, 'product_B': 4})\n",
      "({'product_A': 6, 'product_B': 4}, {'product_A': 1, 'product_B': 0}, 5, {'product_A': 6, 'product_B': 4})\n",
      "({'product_A': 6, 'product_B': 4}, {'product_A': 0, 'product_B': 1}, 18, {'product_A': 6, 'product_B': 4})\n",
      "({'product_A': 6, 'product_B': 4}, {'product_A': 0, 'product_B': 1}, 18, {'product_A': 6, 'product_B': 4})\n",
      "({'product_A': 6, 'product_B': 4}, {'product_A': 1, 'product_B': 0}, 5, {'product_A': 6, 'product_B': 4})\n",
      "({'product_A': 6, 'product_B': 4}, {'product_A': 2, 'product_B': 0}, 15, {'product_A': 6, 'product_B': 4})\n",
      "({'product_A': 6, 'product_B': 4}, {'product_A': 1, 'product_B': 1}, 13, {'product_A': 6, 'product_B': 4})\n"
     ]
    }
   ],
   "source": [
    "# Generar episodios y recolectar datos\n",
    "env = InventoryEnvironment()\n",
    "episodes = [generate_episode(env, random_policy) for _ in range(100)]\n",
    "\n",
    "# Mostrar un ejemplo de episodio\n",
    "for step in episodes[0]:\n",
    "    print(step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exploring_starts(env, num_episodes=100, max_steps=10):\n",
    "    episodes = []\n",
    "    for _ in range(num_episodes):\n",
    "        state = {product: random.randint(0, env.max_stock) for product in env.products}\n",
    "        action = {product: random.randint(0, 2) for product in env.products}\n",
    "        episode = []\n",
    "        for _ in range(max_steps):\n",
    "            next_state, reward = env.step(action)\n",
    "            episode.append((state, action, reward, next_state))\n",
    "            state = next_state\n",
    "            action = random_policy(state)\n",
    "        episodes.append(episode)\n",
    "    return episodes\n",
    "\n",
    "# Generar episodios con Exploring Starts\n",
    "exploring_episodes = exploring_starts(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def epsilon_greedy_policy(state, epsilon=0.1):\n",
    "    if random.random() < epsilon:\n",
    "        return random_policy(state)\n",
    "    else:\n",
    "        return {product: 1 for product in state.keys()}\n",
    "\n",
    "# Generar episodios usando epsilon-greedy\n",
    "def generate_episode_with_epsilon(env, policy, epsilon=0.1, max_steps=10):\n",
    "    state = env.reset()\n",
    "    episode = []\n",
    "    for _ in range(max_steps):\n",
    "        action = policy(state, epsilon)\n",
    "        next_state, reward = env.step(action)\n",
    "        episode.append((state, action, reward, next_state))\n",
    "        state = next_state\n",
    "    return episode\n",
    "\n",
    "epsilon_episodes = [generate_episode_with_epsilon(env, epsilon_greedy_policy) for _ in range(100)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Política objetivo (siempre reponer a nivel 1 por ejemplo)\n",
    "def target_policy(state):\n",
    "    return {product: 1 for product in state.keys()}\n",
    "\n",
    "# Generar episodios usando aprendizaje off-policy\n",
    "def generate_off_policy_episode(env, behavior_policy, target_policy, epsilon=0.1, max_steps=10):\n",
    "    state = env.reset()\n",
    "    episode = []\n",
    "    for _ in range(max_steps):\n",
    "        action = behavior_policy(state, epsilon)\n",
    "        next_state, reward = env.step(action)\n",
    "        episode.append((state, action, reward, next_state))\n",
    "        state = next_state\n",
    "    return episode\n",
    "\n",
    "off_policy_episodes = [generate_off_policy_episode(env, epsilon_greedy_policy, target_policy) for _ in range(100)]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
